{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903bcc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Mesh_refine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Mesh_refine.py\n",
    "\n",
    "# Some rules about the mesh refinement:\n",
    "# 1. A percentaje of the faces must be refined and 4 new triangles are born\n",
    "#    where 3 new points are added in each edge center, and the input data is the residual\n",
    "#        .                  ___ .____\n",
    "#       /\\                 |\\  /\\  /|\n",
    "#      /  \\      Results   | \\/__\\/ |\n",
    "#     /    \\       in      | /\\  /\\ |\n",
    "#    /______\\              |/__\\/__\\|\n",
    "\n",
    "#     in the solvation energy.\n",
    "# 2. Adjacent triangles are split but half UNLESS:\n",
    "#    2.1 They are adjacent to 2 triangles to be refinated into 4 new triangles\n",
    "# Do this until there is no more triangles in 2.1 .\n",
    "\n",
    "# Also, the possibility to extrapolate the point to the real boundary will be\n",
    "# set in a function named new_point()\n",
    "\n",
    "# 11-09 Adjoint mesh usefull\n",
    "\n",
    "#import bempp.api\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import os\n",
    "import time\n",
    "\n",
    "def search_unique_position_in_array(array , main_array):\n",
    "    '''\n",
    "    -\n",
    "    '''\n",
    "    \n",
    "    c=0\n",
    "    array_is_contained = False\n",
    "    \n",
    "    for sub_array in main_array:\n",
    "        \n",
    "        sub_array_counter = 0\n",
    "        \n",
    "        equality = True\n",
    "        for i in sub_array:\n",
    "            \n",
    "            if not isclose( array[sub_array_counter] , sub_array[sub_array_counter]  ):\n",
    "                equality = False\n",
    "                continue\n",
    "                \n",
    "            sub_array_counter+=1\n",
    "            \n",
    "        if equality:\n",
    "            array_is_contained = True\n",
    "            break\n",
    "        c+=1\n",
    "        \n",
    "    if array_is_contained:\n",
    "        return c\n",
    "    \n",
    "    else: \n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    \n",
    "def isclose(a, b, rel_tol=1e-5, abs_tol=0.0):\n",
    "    return abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)\n",
    "    \n",
    "def search_multiple_positions_in_array( arrays , main_array ):\n",
    "    '''\n",
    "    Returns the position of each array (contained in arrays) in main_array.\n",
    "    Arrays must save the information in rows, for example\n",
    "    arrays = np.array((f1x , f1y , f1z),\n",
    "                       f2x , f2y , f2z)....)\n",
    "    '''    \n",
    "    \n",
    "    positions = (-1)*np.ones( (len(arrays),1) )\n",
    "    \n",
    "    i=0\n",
    "    for array in arrays:\n",
    "        \n",
    "        c = 0\n",
    "        \n",
    "        for sub_array in main_array:\n",
    "            \n",
    "            if(array == sub_array).all():\n",
    "                positions[i] = c                \n",
    "            \n",
    "            c+=1\n",
    "        i+=1\n",
    "    return positions\n",
    "\n",
    "def common_verts_between_2_triangles( face_1 , face_2 ):\n",
    "    '''\n",
    "    Returns the 2 common positions in face_1 and face_2\n",
    "    '''\n",
    "    common_verts = np.zeros( (2, ) )\n",
    "    c = 0    \n",
    "    for i in face_1:\n",
    "        for j in face_2:\n",
    "            if i==j and i not in common_verts:\n",
    "                common_verts[c] = i\n",
    "                c+=1\n",
    "                \n",
    "    return common_verts.astype(int)\n",
    "\n",
    "def vert_to_array(mol_name , total_suffix , txt_format , info_type=float):\n",
    "    '''\n",
    "    Rutine which builds the vert array from text files that contain the vert data\n",
    "    mol_name : Abreviated name of the molecule\n",
    "    total_suffix   : text added after molecule name, for an easier handling of files \n",
    "                     may be taken as a total and used like _{density}-{it_count}\n",
    "    txt_format : file format\n",
    "    info_type  : float or int\n",
    "    '''\n",
    "    vert_array = np.loadtxt( os.path.join(path , mol_name +total_suffix + txt_format) )\n",
    "    \n",
    "    return vert_array\n",
    "        \n",
    "def text_to_list(mol_name , total_suffix , txt_format , info_type=float):\n",
    "    '''\n",
    "    Rutine which builds lists from text files that contain the vert and face info\n",
    "    mol_name : Abreviated name of the molecule\n",
    "    total_suffix   : text added after molecule name, for an easier handling of files \n",
    "                     may be taken as a total and used like _{density}-{it_count}\n",
    "    txt_format : file format\n",
    "    info_type  : float or int\n",
    "    '''\n",
    "    path = os.path.join('Molecule',mol_name)\n",
    "    \n",
    "    list_txt = open( os.path.join(path , mol_name +total_suffix + txt_format) ).read().split('\\n')\n",
    "\n",
    "    listing = np.empty((0,3))\n",
    "    for line in list_txt[:-1]:\n",
    "        info    = np.array(line.split()[:3])\n",
    "        listing = np.vstack( ( listing , info ) ).astype(info_type)\n",
    "    return listing\n",
    "\n",
    "def value_assignor_starter(face_array , soln , percentaje):\n",
    "    '''\n",
    "    Assigns face's value to the number of new triangles born (Desirable is 0, 2 or 4).\n",
    "    May use first!\n",
    "    '''\n",
    "    \n",
    "    refined_faces = np.zeros( (len(soln), ) )\n",
    "    \n",
    "    if   type(percentaje) == int:\n",
    "        \n",
    "        listing    = np.zeros( (2 , len(soln)) )\n",
    "        listing[0] = soln\n",
    "        listing[1] = np.arange(len(soln))\n",
    "        listing = sorted (zip(*listing), key = lambda x: x[0])\n",
    "        #listing.sort(key=lambda x: x[0])\n",
    "        #sorted(listing, key=lambda x: x[0])\n",
    "        listing = np.array(listing)\n",
    "        counter = 0\n",
    "        for face in listing[:,1][::-1]:\n",
    "\n",
    "            refined_faces[int(face)] = 4\n",
    "            \n",
    "            if counter+1 == percentaje:\n",
    "                break\n",
    "            counter+=1\n",
    "        \n",
    "        return refined_faces\n",
    "    \n",
    "    elif type(percentaje) == float:\n",
    "        \n",
    "        percentaje_sum = 0.0\n",
    "        \n",
    "        listing    = np.zeros( (2 , len(soln)) )\n",
    "        listing[0] = soln / np.sum( soln )  \n",
    "        listing[1] = np.arange(len(soln))\n",
    "        listing = sorted (zip(*listing), key = lambda x: x[0])\n",
    "        #listing = zip(*listing)\n",
    "        #listing.sort(key=lambda x: x[0])\n",
    "        #sorted (listing, key=lambda x: x[0])\n",
    "        listing = np.array(listing)[::-1]\n",
    "        \n",
    "        counter = 0\n",
    "        for face in listing[:,1]:\n",
    "            \n",
    "            refined_faces[int(face)] = 4\n",
    "            percentaje_sum += listing[ counter , 0 ]\n",
    "            \n",
    "            if percentaje_sum > percentaje:\n",
    "                break\n",
    "            \n",
    "            counter +=1\n",
    "        \n",
    "        return refined_faces\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        # This was used for past versions and refines a percentaje of the faces,\n",
    "        # this was changed to the faces contributing to the total percentaje\n",
    "        \n",
    "        # This extract the class value\n",
    "        #separator = np.sort(soln)[int(percentaje * len(soln) )]\n",
    "        #refined_faces = np.zeros( (len(soln), ) )\n",
    "\n",
    "        #c = 0\n",
    "        #for v in soln:\n",
    "\n",
    "        #    if v>separator:\n",
    "        #        refined_faces[c] = 4\n",
    "        #    c+=1\n",
    "\n",
    "        #return refined_faces\n",
    "\n",
    "    else:\n",
    "        print('Fatal error')\n",
    "\n",
    "        return None\n",
    "    \n",
    "    \n",
    "def coincidence_between_1D_arrays(array1 , array2 , coinc_num ):\n",
    "    '''\n",
    "    Search for coincidences between 2 arrays, returns True if arrays have coinc_num of coincidences\n",
    "    and also returns the coincidences.\n",
    "    '''\n",
    "    coincidences = np.zeros( (coinc_num , ) ) \n",
    "    \n",
    "    c=0\n",
    "    for a1 in array1:\n",
    "        \n",
    "        for a2 in array2:\n",
    "            \n",
    "            if a1 == a2:\n",
    "                \n",
    "                coincidences[c] = a1\n",
    "                c+=1\n",
    "                \n",
    "    if 0 in coincidences:\n",
    "        return False , np.zeros( (coinc_num , ) )\n",
    "                \n",
    "    return True , coincidences\n",
    "\n",
    "def adjacent_faces(face_num , face_array , return_face_number):\n",
    "    '''\n",
    "    Searchs for adjacent faces to be refined and sets value 2 if the face is adjacent to only 1\n",
    "    face which has 4 new triangles to be refined or 3 if this points has a 2 adj. faces to be refined, and \n",
    "    4 if the face has three adj triangles to be refined.\n",
    "    face_num    : Position of the face in face_array\n",
    "    face_status : Face position in face_array to be refined into 4 triangles\n",
    "    return_face_number : Boolean True  if it is required to return the position of the face in face_array.\n",
    "    '''\n",
    "    \n",
    "    adj_faces = np.zeros( (len(face_array), ) )\n",
    "    \n",
    "    pointed_face = face_array[face_num]\n",
    "        \n",
    "    adj = True\n",
    "        \n",
    "    T1 , T2 , T3 = -1 , -1 , -1\n",
    "        \n",
    "    cj = 0\n",
    "        \n",
    "    for face in face_array:\n",
    "                        \n",
    "        if (face == pointed_face).all():\n",
    "            cj+=1\n",
    "            continue\n",
    "            \n",
    "        Boolean , coincidences = coincidence_between_1D_arrays(pointed_face , face , coinc_num=2 )\n",
    "        \n",
    "        if Boolean and T1 == -1:\n",
    "            T1 = cj\n",
    "            cj+=1\n",
    "            continue\n",
    "        if Boolean and T2 == -1:\n",
    "            T2 = cj\n",
    "            cj+=1\n",
    "            continue\n",
    "        if Boolean and T3 == -1:\n",
    "            T3 = cj\n",
    "            cj+=1\n",
    "            continue\n",
    "        \n",
    "        #if f1 in pointed_face:\n",
    "                \n",
    "        #    if (f2 in pointed_face or f3 in pointed_face) and T1 == -1:\n",
    "        #        T1 = cj\n",
    "        #        cj+= 1\n",
    "        #        continue\n",
    "    \n",
    "        #if f2 in pointed_face:\n",
    "                \n",
    "        #    if (f1 in pointed_face or f3 in pointed_face) and T2 == -1:\n",
    "        #        T2 = cj\n",
    "        #        cj+= 1\n",
    "        #        continue\n",
    "                \n",
    "        #if f3 in pointed_face:\n",
    "        #    print('third cond ', face, pointed_face)\n",
    "        #    if f1 in pointed_face or f2 in pointed_face:\n",
    "        #        print('T3: ',face)\n",
    "        #        T3 = cj\n",
    "        #        continue\n",
    "        cj+=1\n",
    "    \n",
    "    adj_faces[T1] , adj_faces[T2] , adj_faces[T3] = 2 , 2 , 2 \n",
    "    \n",
    "    \n",
    "    if return_face_number:\n",
    "        return T1,T2,T3\n",
    "    \n",
    "    else:\n",
    "        return adj_faces\n",
    "\n",
    "def adj_assigner_value( face_array , soln , percentaje):\n",
    "    '''\n",
    "    Gives each face a value depending of its solution value\n",
    "    face_array : Array containing vertex position on a array of vertices\n",
    "    soln       : Quantity/Face atribute to be the criteria to refinate\n",
    "    percetaje  : Percentaje of the mainly faces contributing to error (if float) or\n",
    "                 number of faces to be refined\n",
    "    '''\n",
    "    \n",
    "    first_status = value_assignor_starter(face_array , soln , percentaje)\n",
    "    \n",
    "    adj_status   = np.zeros( (len(face_array), ) )\n",
    "    \n",
    "    face_num = 0    # face counter\n",
    "    \n",
    "    for value in first_status:\n",
    "        \n",
    "        if value == 4:\n",
    "            \n",
    "            adj1 , adj2 , adj3 = adjacent_faces( face_num , face_array , return_face_number = True)\n",
    "            \n",
    "            if adj_status[adj1] != 4:\n",
    "                adj_status[adj1] +=1\n",
    "                \n",
    "            if adj_status[adj2] != 4:\n",
    "                adj_status[adj2] +=1\n",
    "                \n",
    "            if adj_status[adj3] != 4:\n",
    "                adj_status[adj3] +=1\n",
    "            \n",
    "            \n",
    "        face_num+=1\n",
    "        \n",
    "    return adj_status \n",
    "        \n",
    "def final_status(face_array , soln , percentaje ):\n",
    "    '''\n",
    "    Runs into status until there is no more triangles splitted in 3 (rule 2.1)\n",
    "    '''\n",
    "    \n",
    "    status = value_assignor_starter(face_array , soln , percentaje )+  \\\n",
    "                adj_assigner_value(face_array, soln , percentaje)\n",
    "    \n",
    "    face_num = 0\n",
    "    aux_status = status.copy()\n",
    "    for s in status:\n",
    "        if s >4:\n",
    "            aux_status[face_num] = 4\n",
    "        face_num+=1\n",
    "        \n",
    "    status = aux_status.copy().astype(int)        \n",
    "    \n",
    "    iteration_restrictor = 0\n",
    "    \n",
    "    Calculating = True\n",
    "    \n",
    "    while (2 in status or 3 in status) and iteration_restrictor<50 or Calculating:\n",
    "        \n",
    "        if iteration_restrictor == 15:\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            print('Adapting the mesh is taking too long! - Breaking ')\n",
    "            \n",
    "        # Changing the 2 values for 4\n",
    "        \n",
    "        face_num = 0\n",
    "        aux_status = status.copy()\n",
    "        for s in status:\n",
    "            if s == 2 or s == 3 :\n",
    "                aux_status[face_num] = 4\n",
    "            face_num += 1\n",
    "        \n",
    "        Calculating = True\n",
    "        \n",
    "        status = aux_status.copy()\n",
    "        \n",
    "        adj_status   = np.zeros( (len(face_array), ) )\n",
    "        status_4     = np.zeros( (len(face_array), ) )\n",
    "        \n",
    "        face_num = 0\n",
    "        for value in status:\n",
    "        \n",
    "            if value == 4:\n",
    "\n",
    "                adj1 , adj2 , adj3 = adjacent_faces( face_num , face_array , return_face_number = True)\n",
    "\n",
    "                if status[adj1] != 4:\n",
    "                    adj_status[adj1] +=1\n",
    "\n",
    "                if status[adj2] != 4:\n",
    "                    adj_status[adj2] +=1\n",
    "\n",
    "                if status[adj3] != 4:\n",
    "                    adj_status[adj3] +=1\n",
    "                    \n",
    "                status_4[face_num] = 4\n",
    "            face_num+=1\n",
    "\n",
    "        status = adj_status + status_4  \n",
    "            \n",
    "        face_num = 0\n",
    "        aux_status = status.copy()\n",
    "        for s in status:\n",
    "            if s>4:\n",
    "                aux_status[face_num] = 4\n",
    "                \n",
    "            face_num+=1\n",
    "        \n",
    "        status = aux_status.copy()\n",
    "        \n",
    "        iteration_restrictor += 1\n",
    "        \n",
    "        Calculating = False\n",
    "        \n",
    "    return aux_status\n",
    "\n",
    "\n",
    "##esto puede quedar mejor con bempp.refine, ver.\n",
    "def mesh_refiner(face_array , vert_array , soln , percentaje ):\n",
    "    '''\n",
    "    Refines the mesh\n",
    "    '''\n",
    "    \n",
    "    status = final_status(face_array , soln , percentaje )\n",
    "    \n",
    "    new_faces_array = np.empty((0,3))\n",
    "    new_vert_array = vert_array.copy()\n",
    "    \n",
    "    aux_face_array = face_array.copy()\n",
    "    \n",
    "    face_counter = 0\n",
    "    \n",
    "    for face in face_array:\n",
    "        \n",
    "        \n",
    "        if status[face_counter] == 1:\n",
    "             \n",
    "            adj_1_pos , adj_2_pos , adj_3_pos = adjacent_faces( face_counter , face_array , True )\n",
    "            \n",
    "            #Search for the adjacent face that has status 4\n",
    "            \n",
    "            if status[adj_1_pos] == 4:\n",
    "                ady_face = face_array[adj_1_pos]\n",
    "                \n",
    "            elif status[adj_2_pos] == 4:\n",
    "                ady_face = face_array[adj_2_pos]\n",
    "                \n",
    "            elif status[adj_3_pos] == 4:\n",
    "                ady_face = face_array[adj_3_pos]\n",
    "                \n",
    "            # Now search for the 2 common vertex\n",
    "            v1_pos , v2_pos = common_verts_between_2_triangles( ady_face , face ) - 1 \n",
    "            #v1_pos and v2_pos have an absolute value - starts from 0\n",
    "            \n",
    "            \n",
    "            \n",
    "            v1 , v2 = vert_array[v1_pos] , vert_array[v2_pos]\n",
    "            \n",
    "            for v3_pos in face-1:\n",
    "                if v3_pos!=v1_pos and v3_pos!=v2_pos:\n",
    "                    break      \n",
    "            \n",
    "            new_vert = newvert( v1 , v2 )\n",
    "            \n",
    "            # Now let's check if this new vert is already in new_vert_array\n",
    "            test_position = search_unique_position_in_array(new_vert , new_vert_array )\n",
    "            \n",
    "            if test_position == -1:\n",
    "                new_vert_array = np.vstack( (new_vert_array , new_vert ) )\n",
    "                test_position = len(new_vert_array)-1  #test_position is also absolute\n",
    "                \n",
    "                \n",
    "            #Because v1_pos and v2_pos are random-like positions, let's sort it \n",
    "            # using a case by case test\n",
    "            f1 , f2 , f3 = face - 1    \n",
    "            \n",
    "            if   (f1 == v1_pos and f2 == v2_pos) or (f1 == v2_pos and f2 == v1_pos):\n",
    "                \n",
    "                new_face_1 = np.array( ( f1            , test_position , f3  ) ) +1\n",
    "                new_face_2 = np.array( ( test_position , f2            , f3  ) ) +1\n",
    "                \n",
    "            elif (f2 == v1_pos and f3 == v2_pos) or (f2 == v2_pos and f3 == v1_pos):\n",
    "                \n",
    "                new_face_1 = np.array( ( f2            , test_position , f1 ) ) +1\n",
    "                new_face_2 = np.array( ( f1            , test_position , f3 ) ) +1 \n",
    "                \n",
    "            elif (f3 == v1_pos and f1 == v2_pos) or (f3 == v2_pos and f1 == v1_pos):\n",
    "                 \n",
    "                new_face_1 = np.array( ( f3            , test_position , f2 ) ) +1\n",
    "                new_face_2 = np.array( ( f2            , test_position , f1 ) ) +1\n",
    "            \n",
    "            new_faces_array = np.vstack((new_faces_array , new_face_1 ))\n",
    "            new_faces_array = np.vstack((new_faces_array , new_face_2 ))\n",
    "            \n",
    "            # Also we have to delete the face, so let's assign the value (0,0,0) the deleted face\n",
    "            aux_face_array[face_counter] = np.array((0,0,0))\n",
    "                \n",
    "        if status[face_counter] == 4:\n",
    "            \n",
    "            f1 , f2 , f3 = face_array[face_counter] - 1  # Absolute position in vert_array\n",
    "            v1 , v2 , v3 = vert_array[f1] , vert_array[f2] , vert_array[f3]\n",
    "            \n",
    "            new_vert_12 = newvert( v1 , v2 )\n",
    "            new_vert_13 = newvert( v1 , v3 )\n",
    "            new_vert_23 = newvert( v2 , v3 )\n",
    "            \n",
    "            # Let's check like in status == 1 if the new_vert_ij is in new_vert_array:\n",
    "            \n",
    "            pos = np.array((-1,-1,-1))\n",
    "            c = 0\n",
    "            for vert in (new_vert_12 , new_vert_13 , new_vert_23):\n",
    "                test_position = search_unique_position_in_array( vert , new_vert_array )\n",
    "                if test_position == -1:\n",
    "                    new_vert_array = np.vstack( (new_vert_array , vert ) )\n",
    "                    test_position = len(new_vert_array) - 1 # Absolute value!\n",
    "                    \n",
    "                pos[c] = test_position\n",
    "                c+=1\n",
    "            \n",
    "            v12_pos , v13_pos , v23_pos = pos\n",
    "            \n",
    "            new_face_1 = np.array( ( f1     , v12_pos , v13_pos ) ) + 1 \n",
    "            new_face_2 = np.array( ( v12_pos, v23_pos , v13_pos ) ) + 1\n",
    "            new_face_3 = np.array( ( v12_pos, f2      , v23_pos ) ) + 1\n",
    "            new_face_4 = np.array( ( v13_pos, v23_pos , f3      ) ) + 1\n",
    "            \n",
    "            new_faces_array = np.vstack( ( new_faces_array , new_face_1 ) )\n",
    "            new_faces_array = np.vstack( ( new_faces_array , new_face_2 ) )\n",
    "            new_faces_array = np.vstack( ( new_faces_array , new_face_3 ) )\n",
    "            new_faces_array = np.vstack( ( new_faces_array , new_face_4 ) )\n",
    "            \n",
    "            # Also we have to delete the face, so let's assign the value (0,0,0) the deleted face\n",
    "            aux_face_array[face_counter] = np.array((0,0,0))\n",
    "            \n",
    "        face_counter+=1\n",
    "    \n",
    "    final_face_array = np.empty((0,3))\n",
    "    \n",
    "    for face in aux_face_array:\n",
    "        if (face.astype(int) == np.array( (0 , 0 , 0 ) ) ).all():\n",
    "            continue\n",
    "        final_face_array = np.vstack( (final_face_array , face ) )\n",
    "        \n",
    "    for new_face in new_faces_array:\n",
    "        final_face_array = np.vstack( (final_face_array , new_face ) )\n",
    "        \n",
    "    return final_face_array.astype(int) , new_vert_array\n",
    "\n",
    "\n",
    "def newvert(vA,vB):\n",
    "    return 0.5*(vA+vB)\n",
    " \n",
    "def smoothing_vertex( new_vert_array , fine_vert_array, N ):\n",
    "    '''\n",
    "    Smooths verts from a finer mesh\n",
    "    '''\n",
    "    #print (new_vert_array)\n",
    "    #N = tamaño malla no refinada (inicial)\n",
    "    smoothed_vert_array = np.zeros((len(new_vert_array),3))\n",
    "    \n",
    "    smoothed_vert_array[:N,:] = new_vert_array[:N,:]\n",
    "    c=0\n",
    "    for vert in new_vert_array[N:]:\n",
    "        #init_time_0 = time.time()\n",
    "        #print (vert)\n",
    "        #print (fine_vert_array)\n",
    "        radii_i = np.linalg.norm( vert - fine_vert_array , axis = 1)\n",
    "        min_radii = np.min(radii_i)\n",
    "        \n",
    "        #print('radio minimo = {0:.10f}'.format(min_radii))\n",
    "        index_min = np.where(abs(radii_i) < min_radii + 1.e-12)\n",
    "        smoothed_vert_array[N+c,:] = fine_vert_array[index_min[0][0]]\n",
    "\n",
    "        test = np.where(np.abs(smoothed_vert_array[N+c,:] - smoothed_vert_array[N:]) < 1e-12)[0]\n",
    "        if len(test) >=6:\n",
    "            min_radii_anterior = np.sort(radii_i)[1]\n",
    "            index_min_anterior = (np.where(abs(radii_i) < min_radii_anterior + 1.e-12))\n",
    "            smoothed_vert_array[N+c,:] = fine_vert_array[index_min_anterior[0][1]]\n",
    "        \n",
    "        #smoothing_time = time.time()-init_time_0\n",
    "        #print('Smoothing time per element: {0:.10f}'.format(smoothing_time))\n",
    "        c+=1  \n",
    "    #print (smoothed_vert_array[N:])\n",
    "    \n",
    "    return smoothed_vert_array \n",
    "    \n",
    "def is_interior_triangle(adj_vertices , local_vert_array):\n",
    "    '''\n",
    "    Returns true if the designed triangle from the adjoint mesh is totally inside the normal triangle.\n",
    "    adj_vertices : Three vertices from the same elements\n",
    "    local_vert_array   : Array of vertices for a given triangle.\n",
    "    '''\n",
    "    \n",
    "    v1a , v2a, v3a = adj_vertices\n",
    "    v1 , v2 , v3 = local_vert_array\n",
    "    \n",
    "    v12 , v13 , v23 = 0.5*(v1+v2) , 0.5*(v1+v3) , 0.5*(v2+v3)\n",
    "    \n",
    "    c=0\n",
    "    for adj_vertex in adj_vertices:\n",
    "        for vert in (v1, v2 , v3 , v12 , v13 , v23 ):\n",
    "            if isclose(adj_vertex , vert):\n",
    "                print(adj_vertex , vert)\n",
    "                c+=1\n",
    "    if c == 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def elements_position_in_normal_grid(adj_face_array , adj_vert_array , face_array , vert_array ):\n",
    "    '''\n",
    "    Returns the element for which the adjoint element is contained.\n",
    "    inputs:\n",
    "    adj_face_array , adj_vert_array , face_array , vert_array\n",
    "    '''\n",
    "    c=0\n",
    "\n",
    "    adj_relation = np.zeros((len(adj_face_array) , ))\n",
    "\n",
    "    for element in face_array:\n",
    "        f1 , f2 , f3 = element - 1\n",
    "        v1 , v2 , v3 = vert_array[f1] , vert_array[f2] , vert_array[f3]\n",
    "        v12 , v13 , v23 = 0.5*(v1+v2) , 0.5*(v1+v3) , 0.5*(v2+v3)\n",
    "\n",
    "        count_face = 0\n",
    "        for adj_element in adj_face_array:\n",
    "            f1a , f2a , f3a = adj_element - 1\n",
    "            v1a , v2a , v3a = adj_vert_array[f1a] , adj_vert_array[f2a] , adj_vert_array[f3a]\n",
    "\n",
    "\n",
    "            if (search_unique_position_in_array(v1a ,(v1 , v2 , v3 , v12 , v13 , v23) )!= -1 and\n",
    "                search_unique_position_in_array(v2a ,(v1 , v2 , v3 , v12 , v13 , v23) )!= -1 and\n",
    "                search_unique_position_in_array(v3a ,(v1 , v2 , v3 , v12 , v13 , v23) )!= -1):\n",
    "                adj_relation[count_face] = c\n",
    "\n",
    "            count_face +=1\n",
    "\n",
    "        c+=1\n",
    "\n",
    "    return adj_relation\n",
    "\n",
    "\n",
    "def normals(face_array , vert_array):\n",
    "    '''\n",
    "    Returns an array (N,3) containing the normal vectors to each face.\n",
    "    '''\n",
    "    \n",
    "    normals_array = np.empty((0,3))\n",
    "    for f in face_array:\n",
    "        f1 , f2 , f3 = f\n",
    "\n",
    "        v1 , v2 , v3 = vert_array[f1] , vert_array[f2] , vert_array[f3]\n",
    "        \n",
    "        normal = np.cross(v2-v1 , v3 - v1 )\n",
    "    \n",
    "        unit_n = normal/np.linalg.norm(normal)\n",
    "        \n",
    "        normals_array = np.vstack((normals_array , unit_n))\n",
    "    \n",
    "    return normals_array.astype(float)\n",
    "\n",
    "def check_coplanar(triangle_1 , triangle_2 , n_1):\n",
    "    \n",
    "    v1_1 , v1_2 , v1_3 = triangle_1\n",
    "    \n",
    "    coplanar = True\n",
    "    \n",
    "    for point in triangle_2:\n",
    "        \n",
    "        condition = np.dot(n_1 , point - v1_1)\n",
    "        \n",
    "        if condition > 10.**-6:\n",
    "            coplanar = False\n",
    "            break\n",
    "            \n",
    "    return coplanar\n",
    "\n",
    "def Area_of_a_Triangle(A,B,C):\n",
    "    '''\n",
    "    Returns the Area of a triangle for a trio of vertices.\n",
    "    Params: \n",
    "    Vertex_1 , Vertex_2 , Vertex_3\n",
    "    '''\n",
    "    AB = B-A\n",
    "    AC = C-A\n",
    "    return 0.5 * np.linalg.norm( np.cross(AB,AC))\n",
    "\n",
    "\n",
    "\n",
    "def check_contained_triangles_alternative_2(mesh_1 , mesh_2 , N_ref , assume_uniform = True , Tolerance=10**-10\n",
    "                                           ,check_for_unnasigned_faces=True):\n",
    "    '''\n",
    "    Condicion de area y normales para revisar si el triangulo se encuentra dentro de la cara determinada.\n",
    "    Params:\n",
    "    mesh_1 : Coarse mesh\n",
    "    mesh_2 : Finner mesh\n",
    "    N_ref  : Number of refinements\n",
    "    Assume_uniform : True o False\n",
    "    Tolerance : Maximum observable difference between the area triangles and the normals.\n",
    "    '''\n",
    "    face_1 , vert_1 = np.transpose(mesh_1.leaf_view.elements) , np.transpose(mesh_1.leaf_view.vertices)\n",
    "    face_2 , vert_2 = np.transpose(mesh_2.leaf_view.elements) , np.transpose(mesh_2.leaf_view.vertices)\n",
    "    \n",
    "    normal_1 , normal_2 = normals(face_1 , vert_1 ) , normals(face_2 , vert_2)\n",
    "    \n",
    "    relationship = np.zeros((len(face_2),)) - 1\n",
    "    \n",
    "    c1=0\n",
    "    for f1 in face_1:\n",
    "        \n",
    "        v1_1 , v1_2 , v1_3 = vert_1[f1[0]] , vert_1[f1[1]] , vert_1[f1[2]]\n",
    "        \n",
    "        Area_1 = Area_of_a_Triangle(v1_1 , v1_2 , v1_3)\n",
    "        \n",
    "        n_1 = normal_1[c1]\n",
    "        \n",
    "        c2 = 0\n",
    "        for f2 in face_2:\n",
    "            if relationship[c2]<0:\n",
    "                \n",
    "                v2_1 , v2_2 , v2_3 = vert_2[f2[0]] , vert_2[f2[1]] , vert_2[f2[2]]\n",
    "                \n",
    "                n_2 = normal_2[c2]\n",
    "                \n",
    "                condition_counter = 0 \n",
    "                for point in [v2_1 , v2_2 , v2_3]:\n",
    "                    A1 , A2 , A3 = [Area_of_a_Triangle(v1_1,v1_2,point) , \n",
    "                                    Area_of_a_Triangle(v1_1,v1_3,point) ,\n",
    "                                    Area_of_a_Triangle(v1_2,v1_3,point)   ]\n",
    "                    \n",
    "                    if np.abs((A1+A2+A3)-Area_1)<=Tolerance and np.linalg.norm(n_1 - n_2)<=Tolerance:\n",
    "                        condition_counter +=1\n",
    "                \n",
    "                if condition_counter == 3:\n",
    "                    \n",
    "                    relationship[c2] = c1\n",
    "\n",
    "                \n",
    "            c2+=1\n",
    "        c1+=1\n",
    "        \n",
    "    relationship = relationship.astype(int)\n",
    "        \n",
    "    if -1 in relationship:\n",
    "        print('ERROR - DID NOT ASSIGN A FACE TO COARSE MESH')\n",
    "        print(relationship)\n",
    "        \n",
    "    if check_for_unnasigned_faces:\n",
    "        counter_check(relationship , mesh_1 , mesh_2 , N_ref )\n",
    "\n",
    "    if assume_uniform:\n",
    "        counter_check(relationship , mesh_1 , mesh_2 , N_ref)\n",
    "    \n",
    "    return relationship\n",
    "\n",
    "def check_contained_triangles(mesh_1 , mesh_2 , N_ref , assume_uniform = True):\n",
    "    \n",
    "    face_1 , vert_1 = np.transpose(mesh_1.leaf_view.elements) , np.transpose(mesh_1.leaf_view.vertices)\n",
    "    face_2 , vert_2 = np.transpose(mesh_2.leaf_view.elements) , np.transpose(mesh_2.leaf_view.vertices)\n",
    "    \n",
    "    normal_1 , normal_2 = normals(face_1 , vert_1 ) , normals(face_2 , vert_2)\n",
    "    \n",
    "    #print(normal_1 , normal_2)\n",
    "    \n",
    "    relationship = np.zeros((len(face_2),)) - 1\n",
    "    \n",
    "    c1=0\n",
    "    for f1 in face_1:\n",
    "        \n",
    "        v1_1 , v1_2 , v1_3 = vert_1[f1[0]] , vert_1[f1[1]] , vert_1[f1[2]]\n",
    "        \n",
    "        n_1 = normal_1[c1]\n",
    "        \n",
    "        c2 = 0\n",
    "        for f2 in face_2:\n",
    "            if relationship[c2]<0:\n",
    "                n_2 = normal_2[c2]\n",
    "                v2_1 , v2_2 , v2_3 = vert_2[f2[0]] , vert_2[f2[1]] , vert_2[f2[2]]\n",
    "                \n",
    "                if np.linalg.norm(n_1-n_2)<10.**-6 or np.linalg.norm(n_1+n_2)<10.**-6 :\n",
    "                    if check_coplanar([ v1_1 , v1_2 , v1_3 ] , [v2_1 , v2_2 , v2_3] , n_1 ):\n",
    "                        relationship[c2] = c1\n",
    "            c2+=1\n",
    "        c1+=1\n",
    "        \n",
    "    relationship = relationship.astype(int)\n",
    "        \n",
    "    if -1 in relationship:\n",
    "        print('ERROR - DID NOT ASSIGN A FACE TO COARSE MESH')\n",
    "        print(relationship)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if assume_uniform:\n",
    "        counter_check(relationship , mesh_1 , mesh_2 , N_ref)\n",
    "    \n",
    "    #print(relationship)\n",
    "    \n",
    "    return relationship\n",
    "                    \n",
    "def counter_check(relationship , mesh_1 , mesh_2 , N_ref ):\n",
    "    '''\n",
    "    Counts the number of faces assigned to the coarse mesh, for a given number of unifrom refinement cycles.\n",
    "    '''\n",
    "    \n",
    "    check_list = np.zeros(( len(np.transpose(mesh_1.leaf_view.elements)) , 2 )) \n",
    "    \n",
    "    check_list[:,0] = np.arange(0, len(np.transpose(mesh_1.leaf_view.elements)) )\n",
    "    \n",
    "    for i in relationship:\n",
    "        check_list[i,1]+=1\n",
    "    \n",
    "    if np.any(check_list[:,1].astype(int)!=4**N_ref):\n",
    "        \n",
    "        print('ERROR - TRIANGLE ASSIGNED TO OTHER TRIANGLE OF THE COARSE MESH')\n",
    "        print(check_list)\n",
    "        \n",
    "    return None\n",
    "\n",
    "def uniform_refinement_points(v1 , v2 , v3 ):\n",
    "    '''\n",
    "    Creates an array that contains ALL the points generated when doing 1 uniform refinement.\n",
    "    '''\n",
    "    Points = np.array([v1 , v2 , v3 , (v1+v2)/2. , (v2+v3)/2. , (v1+v3)/2.])\n",
    "    N_face = np.array( [[0 , 3 , 5 ] , [3 , 1 , 4] , [4 , 2 , 5] , [3 , 4 , 5] ] )\n",
    "    \n",
    "    sorted_points = np.zeros([4 * 3 , 3])\n",
    "    face_count = 0\n",
    "    for face in N_face:\n",
    "        for f in face:\n",
    "            sorted_points[face_count] = Points[f]\n",
    "            face_count +=1\n",
    "            \n",
    "    return sorted_points\n",
    "\n",
    "def recursive_refinement_points(v1 , v2 , v3 , N_Ref , delete_repeated_points = False ):\n",
    "    '''\n",
    "    Creates an array that contains ALL the points generated when doing N_Ref uniform refinements.\n",
    "    Params:\n",
    "    v1 , v2 , v3 : Vertices\n",
    "    N_Ref : Number of uniform refinements\n",
    "    '''\n",
    "    Ref = 0\n",
    "    \n",
    "    points = np.zeros((4**N_Ref*3 , 3))\n",
    "    points[0] , points[1] , points[2] = v1 , v2 , v3\n",
    "    \n",
    "    while Ref<=N_Ref:\n",
    "        \n",
    "        aux_points = np.zeros((4**N_Ref*3 , 3))\n",
    "        \n",
    "        for c in range(4**(N_Ref-1)):\n",
    "            v1 , v2 , v3 = points[3*c] , points[3*c+1] , points[3*c+2]\n",
    "            \n",
    "            if np.all(np.array([v1,v2,v3])<10**-8):\n",
    "                break\n",
    "        \n",
    "            new_points = uniform_refinement_points( v1 , v2 , v3 )\n",
    "            \n",
    "            for aux_c in range(12):\n",
    "                aux_points[12*c+aux_c] = new_points[aux_c]\n",
    "            \n",
    "        points = aux_points.copy()\n",
    "        \n",
    "        Ref+=1\n",
    "    \n",
    "    if delete_repeated_points:\n",
    "        clean_set = np.empty((0,3))\n",
    "        clean_set = np.vstack((clean_set , points[0] , points[1]))\n",
    "           \n",
    "        for p in points:\n",
    "            \n",
    "            is_contained = False\n",
    "            for clean_p in clean_set:\n",
    "                if np.linalg.norm(clean_p - p ) < 10**-8:\n",
    "                    is_contained = True\n",
    "            if not is_contained:\n",
    "                clean_set = np.vstack([clean_set , p])\n",
    "                \n",
    "            \n",
    "        points=clean_set.copy()\n",
    "        \n",
    "    return points*2\n",
    "\n",
    "def similarities_counter(Small_Array , Big_Array , Tol = 10**-4):\n",
    "    '''\n",
    "    Returns True if all the Small_Array values are contained into the Big_Array for a given\n",
    "    Tolerance\n",
    "    '''\n",
    "    c=0\n",
    "    for small_point in Small_Array:\n",
    "        for big_point in Big_Array:\n",
    "            if np.linalg.norm(big_point-small_point)<Tol:\n",
    "                c+=1\n",
    "    \n",
    "    if c==len(Small_Array)-1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def unitary_refinement_generator(N_ref):\n",
    "    '''\n",
    "    Generates an array containing all the points inside the unitary triangle\n",
    "    (0,0) , (1,0) , (0,1)\n",
    "    Params:\n",
    "    N_ref: Number of refinements\n",
    "    '''\n",
    "    Unit = np.array([ [0.,0.,0.] , [1. , 0. ,0.] , [0.,1., 0.] ])\n",
    "    points = recursive_refinement_points(Unit[0],Unit[1],Unit[2], N_ref , delete_repeated_points=True)\n",
    "    return points\n",
    "\n",
    "def not_lineal_transformation(v1 , v2 , v3 , x_k):\n",
    "    '''\n",
    "    Moves the point x_k from a triangle with vertices [[0,0],[1,0],[0,1]]\n",
    "    to a point in the triangle built by v1,v2,v3\n",
    "    '''\n",
    "    X_k = v1 + (v2-v1)*x_k[0] + (v3-v1)*x_k[1]\n",
    "    return X_k\n",
    "        \n",
    "def check_contained_triangles_alternative(mesh_1 , mesh_2 , N_ref , assume_uniform = True):\n",
    "    \n",
    "    face_1 , vert_1 = np.transpose(mesh_1.leaf_view.elements) , np.transpose(mesh_1.leaf_view.vertices)\n",
    "    face_2 , vert_2 = np.transpose(mesh_2.leaf_view.elements) , np.transpose(mesh_2.leaf_view.vertices)\n",
    "    \n",
    "    normal_1 , normal_2 = normals(face_1 , vert_1 ) , normals(face_2 , vert_2)\n",
    "        \n",
    "    relationship = np.zeros((len(face_2),)) - 1\n",
    "    \n",
    "    unitary_ref_points  = unitary_refinement_generator(N_ref)\n",
    "    \n",
    "    c1=0\n",
    "    for f1 in face_1:\n",
    "        \n",
    "        v1_1 , v1_2 , v1_3 = vert_1[f1[0]] , vert_1[f1[1]] , vert_1[f1[2]]\n",
    "        \n",
    "        n_1 = normal_1[c1]\n",
    "        \n",
    "        aux_points = np.empty([0,3])\n",
    "        for x_k in unitary_ref_points:\n",
    "            aux_points = np.vstack([aux_points ,\n",
    "                                    not_lineal_transformation(v1_1 , v1_2 , v1_3 , x_k) ])      \n",
    "        \n",
    "        \n",
    "        c2 = 0    \n",
    "        for f2 in face_2:\n",
    "            \n",
    "            v2_1 , v2_2 , v2_3 = vert_2[f2[0]] , vert_2[f2[1]] , vert_2[f2[2]]\n",
    "            \n",
    "            n_2 = normal_2[c2]\n",
    "            \n",
    "            if relationship[c2]<0:\n",
    "                \n",
    "                if np.linalg.norm(n_1-n_2)<10**-8:\n",
    "                    \n",
    "                    if similarities_counter(np.array([v2_1 , v2_2 , v2_3]) , aux_points ):                  \n",
    "                        relationship[c2] = c1\n",
    "                            \n",
    "            c2+=1\n",
    "        c1+=1\n",
    "        \n",
    "    relationship = relationship.astype(int)\n",
    "    return relationship\n",
    "\n",
    "\n",
    "def check_contained_triangles__(mesh_1,mesh_2):\n",
    "    '''\n",
    "    BEMPP probable rearrange\n",
    "    '''\n",
    "    face_1 , vert_1 = np.transpose(mesh_1.leaf_view.elements) , np.transpose(mesh_1.leaf_view.vertices)\n",
    "    face_2 , vert_2 = np.transpose(mesh_2.leaf_view.elements) , np.transpose(mesh_2.leaf_view.vertices)\n",
    "    \n",
    "    N_ref = len(face_2)/len(face_1)\n",
    "    \n",
    "    A = np.arange(0,len(face_1))\n",
    "    B = np.ones([ len(face_2)/len(face_1) ,  len(face_1)])\n",
    "\n",
    "    relationship = np.reshape( A*B , len(face_2) , order = 'F'  )\n",
    "    \n",
    "    #print(relationship ) \n",
    "    \n",
    "    return relationship.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e12d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
